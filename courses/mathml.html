<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mathematics for Machine Learning</title>
  <!-- bootstrap -->
  <link rel="stylesheet" href="./css/bootstrap.min.css">
  <link rel="stylesheet" href="./css/bootstrap-theme.min.css">
  <!-- Google fonts -->
  <link href="./css/css" rel="stylesheet" type="text/css">
</head>

<body data-new-gr-c-s-check-loaded="14.996.0" data-gr-ext-installed="">
  <div id="header">
  <div style="background-color:#8C1515; color:#FFF; padding:15px;">
    <h1>Mathematics for Machine Learning</h1>
  </div>
  </div>
  <div class="container sec">
    <h2>Introduction</h2>
<h4>Undergraduate-level or early-graduate-level course on mathematics for machine learning (ML) and basic ML problems.
  </h4>
 <br>
</div>

  <div class="container sec">
    <h2>Textbook</h2>
<h4>I mainly used this book for making lecture materials in terms of contents and organization.</h4>
<h4><a href="https://mml-book.github.io/"> - Mathematics for Machine Learning</a>
  by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong</h4>
<h4> Additionally, I used the following two books to discuss the areas of optimization and probability.</h4>
<h4><a href="https://web.stanford.edu/~boyd/cvxbook/"> - Convex Optimization</a>
  by Stephen Boyd and Lieven Vandenberghe</h4>
<h4><a href="http://athenasc.com/probbook.html"> - Introduction to Probability,</a> 2nd edition
    by Dimitri P. Bertsekas and John N. Tsitsiklis</h4>

<img src="images/mathmlbook.jpg" width="165" height="240" hspace="20"
    alt="images/mathmlbook.jpg" align="left" border="2" hspace="10" vspace="10">
<img src="images/cvxbook.jpg" width="165" height="240" hspace="20"
        alt="images/cvxbook.jpg" align="left" border="2" hspace="10" vspace="10">
<img src="images/probcover-2nd.jpg" width="165" height="240" hspace="20"
            alt="images/probcover-2nd.jpg" align="left" border="2" hspace="10" vspace="10">

<br>

  </div>




<div class="container sec">
    <h2>Lecture Notes Source Files (<a href="https://github.com/yung-web/MathML">Download from Github</a>)</h2>
<h4>They have been made by Prof. Yung Yi, and they are keep being updated now.
  He used most of the contents from the textbook, but more explanatinos/figures/examples are added if necessary.
  When he used the figures of the main textbook, he did not leave any courtesy in the slides, but for other figures, he tried to mention their sources.
  The lecture nodes are being made in the <a href="https://www.overleaf.com">overleaf</a> platform.
</h4>
  </div>



  <div class="container sec">
    <table class="table">
      <tbody>
        <tr class="active">
          <th>Contents &nbsp;</th>
          <!-- <th>Videos&nbsp;</th> -->
          <th>Material &nbsp;</th>
          <th></th>
        </tr>

        <tr>
          <td><h4>1. Introduction and Overview</h4>
            <li> Contents</li>
            <li> Suggestions for course schedules</li>
            <li> Target audience</li>
            <li> Organization of LaTex source files (e.g., how to compile etc)</li>
	  </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/01.Introduction/1.intro.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/01.Introduction/1.intro.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/01.Introduction/1.intro-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/01.Introduction/1.intro-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>2. Linear Algebra</h4>
            <li>Systems of Linear Equations</li>
            <li>Matrices</li>
            <li>Solving Systems of Linear Equations</li>
            <li>Vector Spaces</li>
            <li>Linear Independence</li>
            <li>Basis and Rank</li>
            <li>Linear Mappings</li>
            <li>Affine Spaces</li>
          </td>
          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/02.LinearAlgebra

/2.LA.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/02.LinearAlgebra/2.LA.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/02.LinearAlgebra/2.LA-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/02.LinearAlgebra/2.LA-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>3. Analytic Geometry</h4>
             <li>Norms</li>
             <li>Inner Products</li>
             <li>Lengths and Distances</li>
             <li>Angles and Orthogonality</li>
             <li>Orthonormal Basis</li>
             <li>Orthogonal Complement</li>
             <li>Inner Product of Functions</li>
             <li>Orthogonal Projections</li>
             <li>Rotations</li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/03.Geometry/3.AG.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/03.Geometry/3.AG.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/03.Geometry/3.AG-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/03.Geometry/3.AG-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>4. Matrix Decomposition</h4>
            <li> Determinant and Trace</li>
            <li> Eigenvalues and Eigenvectors</li>
            <li> Cholesky Decomposition</li>
            <li> Eigendecomposition and Diagonalization</li>
            <li> Singular Value Decomposition</li>
            <li> Matrix Approximation</li>
            <li> Matrix Phylogeny</li>

          </td>
          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/04.MatrixDecomposition/4.MD.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/04.MatrixDecomposition/4.MD.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/04.MatrixDecomposition/4.MD-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/04.MatrixDecomposition/4.MD-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>5. Vector Calculus</h4>
            <li> Differentiation of Univariate Functions</li>

            <li> Partial Differentiation and Gradients </li>

            <li> Gradients of Vector-Valued Functions </li>

            <li> Gradients of Matrices </li>

            <li> Useful Identities for Computing Gradients </li>

            <li> Backpropagation and Automatic Differentiation </li>

            <li> Higher-Order Derivatives </li>

            <li> Linearization and Multivariate Taylor Series</li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/05.VectorCaculus/5.VC.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/05.VectorCaculus/5.VC.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/05.VectorCaculus/5.VC-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/05.VectorCaculus/5.VC-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>6. Probability and Distributions</h4>
            <li> Construction of a Probability Space</li>
            <li> Discrete and Continuous Probabilities </li>
            <li> Sum Rule, Product Rule, and Bayesâ€™ Theorem </li>
            <li> Summary Statistics and Independence</li>
            <li> Gaussian Distribution</li>
            <li> Conjugacy and the Exponential Family </li>
            <li> Change of Variables/Inverse Transform </li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/06.Probability/6.PD.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/06.Probability/6.PD.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/06.Probability/6.PD-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/06.Probability/6.PD-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>7. Optimization</h4>
            <li> Optimization Using Gradient Descent </li>
            <li> Constrained Optimization and Lagrange Multipliers </li>
            <li> Convex Sets and Functions</li>
            <li> Convex Optimization </li>
            <li> Convex Conjugate</li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/07.Optimization/7.OPT.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/07.Optimization/7.OPT.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/07.Optimization/7.OPT-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/07.Optimization/7.OPT-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>8. When Models Meet Data</h4>
            <li> Data, Models, and Learning </li>
            <li> Models as Functions: Empirical Risk Minimization </li>
            <li> Models as Probabilistic Models: Parameter Estimation (ML and MAP)</li>
            <li> Probabilistic Modeling and Inference </li>
            <li> Directed Graphical Models </li>
            <li> Model Selection</li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/08.Model_Data/8.MMD.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/08.Model_Data/8.MMD.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/08.Model_Data/8.MMD-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/08.Model_Data/8.MMD-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>9. Linear Regression</h4>
            <li>  Problem Formulation </li>
            <li>  Parameter Estimation: ML </li>
            <li>  Parameter Estimation: MAP </li>
            <li>  Bayesian Linear Regression </li>
            <li>  Maximum Likelihood as Orthogonal Projection </li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/09.LinearRegression/9.LR.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/09.LinearRegression/9.LR.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/09.LinearRegression/9.LR-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/09.LinearRegression/9.LR-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>10. Dimensionality Reduction with Principal Component Analysis</h4>
            <li> Problem Setting </li>
            <li> Maximum Variance Perspective </li>
            <li> Projection Perspective </li>
            <li> Eigenvector Computation and Low-Rank Approximations </li>
            <li> PCA in High Dimensions </li>
            <li> Key Steps of PCA in Practice </li>
            <li> Latent Variable Perspective</li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/10.PCA/10.PCA.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/10.PCA/10.PCA.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/10.PCA/10.PCA-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/10.PCA/10.PCA-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>11. Density Estimation with Gaussian Mixture Models</h4>
            <li> Gaussian Mixture Model</li>
            <li> Parameter Learning: MLE</li>
            <li> Latent-Variable Perspective for Probabilistic Modeling</li>
            <li> EM Algorithm</li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/11.DensityEstimation/11.GMM.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/11.DensityEstimation/11.GMM.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/11.DensityEstimation/11.GMM-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/11.DensityEstimation/11.GMM-4.pdf">4</a></li>
          </td>
        </tr>

        <tr>
          <td><h4>12. Classification with Support Vector Machines</h4>
            <li> Story and Separating Hyperplanes </li>
            <li> Primal SVM: Hard SVM </li>
            <li> Primal SVM: Soft SVM </li>
            <li> Dual SVM </li>
            <li> Kernels </li>
            <li> Numerical Solution </li>
          </td>

          <td>
              <li><a href="https://github.com/yung-web/MathML/blob/main/12.SVM/12.SVM.pdf">Lecture slides</a></li>
              <li>For prints: <a href="https://github.com/yung-web/MathML/blob/main/12.SVM/12.SVM.pdf">1</a>, <a href="https://github.com/yung-web/MathML/blob/main/12.SVM/12.SVM-2.pdf">2</a>, <a href="https://github.com/yung-web/MathML/blob/main/12.SVM/12.SVM-4.pdf">4</a></li>
          </td>
        </tr>

      </tbody>
    </table>
  </div>


</body></html>
